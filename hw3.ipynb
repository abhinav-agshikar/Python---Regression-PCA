{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import scipy.stats as ss\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "\n",
    "import math\n",
    "from ctypes import *\n",
    "import sys\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3191"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_df = pd.read_csv('2015 CHR Analytic Data.csv')\n",
    "len(review_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. TOTAL NUMBER OF COUNTIES:  823\n"
     ]
    }
   ],
   "source": [
    "#Step 1\n",
    "\n",
    "df = review_df # Store in dummy variable\n",
    "df['2011 population estimate Value'] = df[\"2011 population estimate Value\"].str.replace(',','')\n",
    "df['2011 population estimate Value'] = df['2011 population estimate Value'].astype(float)\n",
    "df = df.drop(df[df['2011 population estimate Value'] < 30000].index) # Drop all < 30000\n",
    "#print len(df)\n",
    "\n",
    "#Step 2\n",
    "for column_name, column in df.transpose().iterrows():\n",
    "    if(column_name!='COUNTYCODE' and column_name.find(\"Value\",(len(column_name)-5))==-1):\n",
    "        df = df.drop(column_name, 1)\n",
    "#print len(df)\n",
    "\n",
    "\n",
    "#Step3\n",
    "\n",
    "df= df.dropna()\n",
    "\n",
    "#Delete all total rows\n",
    "\n",
    "df.dropna() #Drop all rows having any Nan\n",
    "df = df.drop(df[df['COUNTYCODE'] == 0].index)\n",
    "print \"1. TOTAL NUMBER OF COUNTIES: \",len(df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2. log_paamv HISTOGRAM: 2histogram.png\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAEACAYAAABWLgY0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\njCEPAAPGkAeAAWPIA8CAMeQBYMD+H0YJBjkk+QE7AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f872aea5210>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['log_paamv'] = df['Premature age-adjusted mortality Value']\n",
    "\n",
    "df['log_paamv']=np.log(df['log_paamv'])\n",
    "df['log_paamv'].hist(bins=20)\n",
    "print \"2. log_paamv HISTOGRAM: 2histogram.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. Non-regularized Linear Regression MSE:  0.124838899866\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets, linear_model\n",
    "\n",
    "#Shuffle Indexes\n",
    "df = df.reindex(np.random.permutation(df.index))\n",
    "#print df.head()\n",
    "\n",
    "REMOVED_COLUMNS = ['COUNTYCODE', 'log_paamv', 'Premature age-adjusted mortality Value','Premature death Value', 'Uninsured adults Value', 'Teen births Value', 'Food insecurity Value', 'Physical inactivity Value', 'Adult smoking Value', 'Injury deaths Value', 'Motor vehicle crash deaths Value', 'Drug poisoning deaths Value', 'Child mortality Value', 'Uninsured Value']\n",
    "lr_df = df.copy()\n",
    "\n",
    "for col_name in REMOVED_COLUMNS:\n",
    "    #print col_name\n",
    "    lr_df = lr_df.drop(col_name, 1)\n",
    "lr_df.head()\n",
    "\n",
    "for c in lr_df.columns:\n",
    "    if not (lr_df[c].dtype == np.float64 or lr_df[c].dtype == np.int64):\n",
    "        lr_df[c] = lr_df[c].apply(lambda val: float(string.replace(str(val),',',''))) ##change to string then floats... \n",
    "        lr_df[c] = lr_df[c].astype('float')\n",
    "\n",
    "\n",
    "#Standardize\n",
    "\n",
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "gMAE = 0.0\n",
    "for j in range(0, 10):\n",
    "    \n",
    "    to_be_skipped_from = int( (j*len(lr_df))/10 )\n",
    "    to_be_skipped = int(len(lr_df)/10)+1\n",
    "    \n",
    "    train_x = lr_df[0:to_be_skipped_from].copy()\n",
    "    train_y = df['log_paamv'][0:to_be_skipped_from].copy()\n",
    "    \n",
    "    train_x = train_x.append(lr_df[to_be_skipped_from+to_be_skipped:len(lr_df)+1].copy())\n",
    "    train_y = train_y.append(df['log_paamv'][to_be_skipped_from+to_be_skipped:len(lr_df)+1].copy())\n",
    "    \n",
    "    test_x = lr_df[to_be_skipped_from:to_be_skipped_from+to_be_skipped].copy()\n",
    "    test_y = df['log_paamv'][to_be_skipped_from:to_be_skipped_from+to_be_skipped].copy()\n",
    "    \n",
    "    for c in train_x.columns:\n",
    "        train_x[c] = (train_x[c] - np.mean(train_x[c]))/np.std(train_x[c])\n",
    "    \n",
    "    train_y = (train_y - np.mean(train_y))/np.std(train_y)\n",
    "        \n",
    "    for c in test_x.columns:\n",
    "        test_x[c] = (test_x[c] - np.mean(test_x[c]))/np.std(test_x[c])\n",
    "        \n",
    "    test_y = (test_y - np.mean(test_y))/np.std(test_y)\n",
    "    \n",
    "    #print 'train_x',0,to_be_skipped_from\n",
    "    #print 'train_x append',to_be_skipped_from+to_be_skipped,len(lr_df)+1\n",
    "    #print 'test_x',to_be_skipped_from,to_be_skipped_from+to_be_skipped\n",
    "    \n",
    "    regr.fit(train_x, train_y)\n",
    "\n",
    "    # The coefficients\n",
    "    #print(\"Residual sum of squares:\",np.mean((regr.predict(test_x) - test_y) ** 2))\n",
    "    gMAE += np.mean((regr.predict(test_x) - test_y) ** 2)\n",
    "\n",
    "gMAE = gMAE/10\n",
    "\n",
    "print \"3. Non-regularized Linear Regression MSE: \", gMAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4. Percentage variance explained of first three components: [ 0.28090638  0.13937027  0.0792126 ]\n"
     ]
    }
   ],
   "source": [
    "#Part 4\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "#Standardize dataset\n",
    "for c in lr_df.columns:\n",
    "    lr_df[c] = (lr_df[c] - np.mean(lr_df[c]))/np.std(lr_df[c])\n",
    "    \n",
    "pca = PCA(n_components=3)\n",
    "pca.fit(lr_df)\n",
    "print \"4. Percentage variance explained of first three components:\", pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5. a) principal components regression mse:  0.126886957947\n"
     ]
    }
   ],
   "source": [
    "#Part 5 a)\n",
    "#PCA\n",
    "from sklearn import datasets, linear_model\n",
    "\n",
    "#Shuffle Indexes\n",
    "df = df.reindex(np.random.permutation(df.index))\n",
    "#print df.head()\n",
    "\n",
    "lr_df = df.copy()\n",
    "#Standardize\n",
    "\n",
    "for col_name in REMOVED_COLUMNS:\n",
    "    #print col_name\n",
    "    lr_df = lr_df.drop(col_name, 1)\n",
    "lr_df.head()\n",
    "\n",
    "for c in lr_df.columns:\n",
    "    if not (lr_df[c].dtype == np.float64 or lr_df[c].dtype == np.int64):\n",
    "        lr_df[c] = lr_df[c].apply(lambda val: float(string.replace(str(val),',',''))) ##change to string then floats... \n",
    "        lr_df[c] = lr_df[c].astype('float')\n",
    "\n",
    "\n",
    "\n",
    "regr = linear_model.LinearRegression()\n",
    "gMAE = 0.0\n",
    "\n",
    "\n",
    "for j in range(0, 10):\n",
    "    \n",
    "    to_be_skipped_from = int( (j*len(lr_df))/10 )\n",
    "    to_be_skipped = int(2*len(lr_df)/10)+1\n",
    "    \n",
    "    if j < 9:\n",
    "        train_x = lr_df[0:to_be_skipped_from].copy()\n",
    "        train_y = df['log_paamv'][0:to_be_skipped_from].copy()\n",
    "\n",
    "        train_x = train_x.append(lr_df[to_be_skipped_from+to_be_skipped:len(lr_df)+1].copy())\n",
    "        train_y = train_y.append(df['log_paamv'][to_be_skipped_from+to_be_skipped:len(lr_df)+1].copy())\n",
    "\n",
    "        test_x = lr_df[to_be_skipped_from:to_be_skipped_from+to_be_skipped/2].copy()\n",
    "        test_y = df['log_paamv'][to_be_skipped_from:to_be_skipped_from+to_be_skipped/2].copy()\n",
    "\n",
    "        dev_x = lr_df[to_be_skipped_from+to_be_skipped/2:to_be_skipped_from+to_be_skipped].copy()\n",
    "        dev_y = df['log_paamv'][to_be_skipped_from+to_be_skipped/2:to_be_skipped_from+to_be_skipped].copy()\n",
    "\n",
    "    else:\n",
    "        to_be_skipped = int(len(lr_df)/10)+1\n",
    "        train_x = lr_df[to_be_skipped+1:len(lr_df)-to_be_skipped].copy()\n",
    "        train_y = df['log_paamv'][to_be_skipped+1:len(lr_df)-to_be_skipped].copy()\n",
    "\n",
    "        test_x = lr_df[len(lr_df)-to_be_skipped+1:len(lr_df)].copy()\n",
    "        test_y = df['log_paamv'][len(lr_df)-to_be_skipped+1:len(lr_df)].copy()\n",
    "\n",
    "        dev_x = lr_df[0:to_be_skipped].copy()\n",
    "        dev_y = df['log_paamv'][0:to_be_skipped].copy()\n",
    "    \n",
    "    for c in train_x.columns:\n",
    "        train_x[c] = (train_x[c] - np.mean(train_x[c]))/np.std(train_x[c])\n",
    "    \n",
    "    train_y = (train_y - np.mean(train_y))/np.std(train_y)\n",
    "        \n",
    "    for c in test_x.columns:\n",
    "        test_x[c] = (test_x[c] - np.mean(test_x[c]))/np.std(test_x[c])\n",
    "        \n",
    "    test_y = (test_y - np.mean(test_y))/np.std(test_y)\n",
    "    \n",
    "    for c in dev_x.columns:\n",
    "        dev_x[c] = (dev_x[c] - np.mean(dev_x[c]))/np.std(dev_x[c])\n",
    "        \n",
    "    dev_y = (dev_y - np.mean(dev_y))/np.std(dev_y)\n",
    "    \n",
    "    #print 'train_x',0,to_be_skipped_from\n",
    "    #print 'train_x append',to_be_skipped_from+to_be_skipped,len(lr_df)+1\n",
    "    #print 'test_x',to_be_skipped_from,to_be_skipped_from+to_be_skipped\n",
    "    min_error = 10000;\n",
    "    min_comp = 1\n",
    "    for k in range(3,44):\n",
    "        pca = PCA(n_components=k)\n",
    "        pca.fit(train_x)\n",
    "        Z = pca.transform(train_x)\n",
    "        Z =  pd.DataFrame(Z).copy()\n",
    "        dev_min = pca.transform(dev_x)\n",
    "        dev_min =  pd.DataFrame(dev_min).copy()\n",
    "        #print 'Z: ', len(Z),' train_y', len(train_y),' train_x', len(train_x)\n",
    "        #print 'dev_x', len(dev_x),' dev_y', len(dev_y)\n",
    "        regr.fit(Z, train_y)\n",
    "        error = np.mean((regr.predict(dev_min) - dev_y) ** 2)\n",
    "        if error < min_error:\n",
    "            min_comp = k\n",
    "            min_error = error\n",
    "    #print 'iter ',j\n",
    "    #print 'min components', min_comp\n",
    "    pca = PCA(n_components=min_comp)\n",
    "    pca.fit(train_x)\n",
    "    Z = pca.transform(train_x)      \n",
    "    Z =  pd.DataFrame(Z).copy()\n",
    "    test_x = pca.transform(test_x)\n",
    "    test_x =  pd.DataFrame(test_x).copy()\n",
    "    regr.fit(Z, train_y)\n",
    "    gMAE += np.mean((regr.predict(test_x) - test_y) ** 2)\n",
    "\n",
    "gMAE = gMAE/10\n",
    "\n",
    "print \"5. a) principal components regression mse: \", gMAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5. b) L2 regularized mse:  0.12111448232\n"
     ]
    }
   ],
   "source": [
    "#Part 5 b)\n",
    "#L2 Regularization\n",
    "\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "\n",
    "#Shuffle Indexes\n",
    "df = df.reindex(np.random.permutation(df.index))\n",
    "#print df.head()\n",
    "\n",
    "lr_df = df.copy()\n",
    "#Standardize\n",
    "\n",
    "for col_name in REMOVED_COLUMNS:\n",
    "    #print col_name\n",
    "    lr_df = lr_df.drop(col_name, 1)\n",
    "lr_df.head()\n",
    "\n",
    "for c in lr_df.columns:\n",
    "    if not (lr_df[c].dtype == np.float64 or lr_df[c].dtype == np.int64):\n",
    "        lr_df[c] = lr_df[c].apply(lambda val: float(string.replace(str(val),',',''))) ##change to string then floats... \n",
    "        lr_df[c] = lr_df[c].astype('float')\n",
    "\n",
    "gMAE = 0.0\n",
    "\n",
    "\n",
    "for j in range(0, 10):\n",
    "    \n",
    "    to_be_skipped_from = int( (j*len(lr_df))/10 )\n",
    "    to_be_skipped = int(2*len(lr_df)/10)+1\n",
    "    \n",
    "    if j < 9:\n",
    "        train_x = lr_df[0:to_be_skipped_from].copy()\n",
    "        train_y = df['log_paamv'][0:to_be_skipped_from].copy()\n",
    "\n",
    "        train_x = train_x.append(lr_df[to_be_skipped_from+to_be_skipped:len(lr_df)+1].copy())\n",
    "        train_y = train_y.append(df['log_paamv'][to_be_skipped_from+to_be_skipped:len(lr_df)+1].copy())\n",
    "\n",
    "        test_x = lr_df[to_be_skipped_from:to_be_skipped_from+to_be_skipped/2].copy()\n",
    "        test_y = df['log_paamv'][to_be_skipped_from:to_be_skipped_from+to_be_skipped/2].copy()\n",
    "\n",
    "        dev_x = lr_df[to_be_skipped_from+to_be_skipped/2:to_be_skipped_from+to_be_skipped].copy()\n",
    "        dev_y = df['log_paamv'][to_be_skipped_from+to_be_skipped/2:to_be_skipped_from+to_be_skipped].copy()\n",
    "\n",
    "    else:\n",
    "        to_be_skipped = int(len(lr_df)/10)+1\n",
    "        train_x = lr_df[to_be_skipped+1:len(lr_df)-to_be_skipped].copy()\n",
    "        train_y = df['log_paamv'][to_be_skipped+1:len(lr_df)-to_be_skipped].copy()\n",
    "\n",
    "        test_x = lr_df[len(lr_df)-to_be_skipped+1:len(lr_df)].copy()\n",
    "        test_y = df['log_paamv'][len(lr_df)-to_be_skipped+1:len(lr_df)].copy()\n",
    "\n",
    "        dev_x = lr_df[0:to_be_skipped].copy()\n",
    "        dev_y = df['log_paamv'][0:to_be_skipped].copy()\n",
    "    \n",
    "    for c in train_x.columns:\n",
    "        train_x[c] = (train_x[c] - np.mean(train_x[c]))/np.std(train_x[c])\n",
    "    \n",
    "    train_y = (train_y - np.mean(train_y))/np.std(train_y)\n",
    "        \n",
    "    for c in test_x.columns:\n",
    "        test_x[c] = (test_x[c] - np.mean(test_x[c]))/np.std(test_x[c])\n",
    "        \n",
    "    test_y = (test_y - np.mean(test_y))/np.std(test_y)\n",
    "    \n",
    "    for c in dev_x.columns:\n",
    "        dev_x[c] = (dev_x[c] - np.mean(dev_x[c]))/np.std(dev_x[c])\n",
    "        \n",
    "    dev_y = (dev_y - np.mean(dev_y))/np.std(dev_y)\n",
    "    \n",
    "    #print 'train_x',0,to_be_skipped_from\n",
    "    #print 'train_x append',to_be_skipped_from+to_be_skipped,len(lr_df)+1\n",
    "    #print 'test_x',to_be_skipped_from,to_be_skipped_from+to_be_skipped\n",
    "    min_error = 10000;\n",
    "    min_alpha = 1\n",
    "    alphas = [pow(10,-5),pow(10,-4),pow(10,-3),pow(10,-2),pow(10,-1),1,10,100,1000,10000,100000,1000000]\n",
    "    for alpha in alphas:\n",
    "        regr = Ridge(alpha=alpha)\n",
    "        regr.fit(train_x, train_y)\n",
    "        error = np.mean((regr.predict(dev_x) - dev_y) ** 2)\n",
    "        if error < min_error:\n",
    "            min_alpha = alpha\n",
    "            min_error = error\n",
    "    #print 'iter ',j\n",
    "    #print 'min alpha', min_alpha\n",
    "    #print 'min error', min_error\n",
    "    regr = Ridge(alpha=min_alpha)\n",
    "    regr.fit(train_x, train_y)\n",
    "    gMAE += np.mean((regr.predict(test_x) - test_y) ** 2)\n",
    "\n",
    "gMAE = gMAE/10\n",
    "\n",
    "print \"5. b) L2 regularized mse: \", gMAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5. b) L1 regularized mse:  0.122738420223\n"
     ]
    }
   ],
   "source": [
    "#Part 5 c)\n",
    "#L1 Regularization\n",
    "\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "\n",
    "#Shuffle Indexes\n",
    "df = df.reindex(np.random.permutation(df.index))\n",
    "#print df.head()\n",
    "\n",
    "lr_df = df.copy()\n",
    "#Standardize\n",
    "\n",
    "for col_name in REMOVED_COLUMNS:\n",
    "    #print col_name\n",
    "    lr_df = lr_df.drop(col_name, 1)\n",
    "lr_df.head()\n",
    "\n",
    "for c in lr_df.columns:\n",
    "    if not (lr_df[c].dtype == np.float64 or lr_df[c].dtype == np.int64):\n",
    "        lr_df[c] = lr_df[c].apply(lambda val: float(string.replace(str(val),',',''))) ##change to string then floats... \n",
    "        lr_df[c] = lr_df[c].astype('float')\n",
    "\n",
    "\n",
    "gMAE = 0.0\n",
    "\n",
    "\n",
    "for j in range(0, 10):\n",
    "    \n",
    "    to_be_skipped_from = int( (j*len(lr_df))/10 )\n",
    "    to_be_skipped = int(2*len(lr_df)/10)+1\n",
    "    \n",
    "    if j < 9:\n",
    "        train_x = lr_df[0:to_be_skipped_from].copy()\n",
    "        train_y = df['log_paamv'][0:to_be_skipped_from].copy()\n",
    "\n",
    "        train_x = train_x.append(lr_df[to_be_skipped_from+to_be_skipped:len(lr_df)+1].copy())\n",
    "        train_y = train_y.append(df['log_paamv'][to_be_skipped_from+to_be_skipped:len(lr_df)+1].copy())\n",
    "\n",
    "        test_x = lr_df[to_be_skipped_from:to_be_skipped_from+to_be_skipped/2].copy()\n",
    "        test_y = df['log_paamv'][to_be_skipped_from:to_be_skipped_from+to_be_skipped/2].copy()\n",
    "\n",
    "        dev_x = lr_df[to_be_skipped_from+to_be_skipped/2:to_be_skipped_from+to_be_skipped].copy()\n",
    "        dev_y = df['log_paamv'][to_be_skipped_from+to_be_skipped/2:to_be_skipped_from+to_be_skipped].copy()\n",
    "\n",
    "    else:\n",
    "        to_be_skipped = int(len(lr_df)/10)+1\n",
    "        train_x = lr_df[to_be_skipped+1:len(lr_df)-to_be_skipped].copy()\n",
    "        train_y = df['log_paamv'][to_be_skipped+1:len(lr_df)-to_be_skipped].copy()\n",
    "\n",
    "        test_x = lr_df[len(lr_df)-to_be_skipped+1:len(lr_df)].copy()\n",
    "        test_y = df['log_paamv'][len(lr_df)-to_be_skipped+1:len(lr_df)].copy()\n",
    "\n",
    "        dev_x = lr_df[0:to_be_skipped].copy()\n",
    "        dev_y = df['log_paamv'][0:to_be_skipped].copy()\n",
    "    \n",
    "    for c in train_x.columns:\n",
    "        train_x[c] = (train_x[c] - np.mean(train_x[c]))/np.std(train_x[c])\n",
    "    \n",
    "    train_y = (train_y - np.mean(train_y))/np.std(train_y)\n",
    "        \n",
    "    for c in test_x.columns:\n",
    "        test_x[c] = (test_x[c] - np.mean(test_x[c]))/np.std(test_x[c])\n",
    "        \n",
    "    test_y = (test_y - np.mean(test_y))/np.std(test_y)\n",
    "    \n",
    "    for c in dev_x.columns:\n",
    "        dev_x[c] = (dev_x[c] - np.mean(dev_x[c]))/np.std(dev_x[c])\n",
    "        \n",
    "    dev_y = (dev_y - np.mean(dev_y))/np.std(dev_y)\n",
    "    \n",
    "    #print 'train_x',0,to_be_skipped_from\n",
    "    #print 'train_x append',to_be_skipped_from+to_be_skipped,len(lr_df)+1\n",
    "    #print 'test_x',to_be_skipped_from,to_be_skipped_from+to_be_skipped\n",
    "    min_error = 10000;\n",
    "    min_alpha = 1\n",
    "    alphas = [pow(10,-5),pow(10,-4),pow(10,-3),pow(10,-2),pow(10,-1),1,10,100,1000,10000,100000]\n",
    "    for alpha in alphas:\n",
    "        regr = Lasso(alpha=alpha)\n",
    "        regr.fit(train_x, train_y)\n",
    "        error = np.mean((regr.predict(dev_x) - dev_y) ** 2)\n",
    "        if error < min_error:\n",
    "            min_alpha = alpha\n",
    "            min_error = error\n",
    "    #print 'iter ',j\n",
    "    #print 'min alpha', min_alpha\n",
    "    #print 'min error', min_error\n",
    "    regr = Lasso(alpha=min_alpha)\n",
    "    regr.fit(train_x, train_y)\n",
    "    gMAE += np.mean((regr.predict(test_x) - test_y) ** 2)\n",
    "\n",
    "gMAE = gMAE/10\n",
    "\n",
    "print \"5. c) L1 regularized mse: \", gMAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
